approach for today: invert at end by saving min and max, then turning prediction matrix A' = 1/A, then renormalizing A' between those boundaries. 
I'm going to make the change after the detect trees step of predict() because it's the least involved aspect of the code to change. 

X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))
X_scaled = X_std * (max - min) + min

Okay based on initial investigation this does not seem like a good approach...it reverses the distribution which is a bad idea. 

maybe my norm func is wrong? 

maybe 2d norm is bad? 