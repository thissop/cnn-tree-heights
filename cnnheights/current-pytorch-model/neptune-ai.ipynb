{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorch_NN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PyTorch_NN, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, 128)\n",
    "        self.hidden_layer = nn.Linear(128, 64)\n",
    "        self.output_layer = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        x = F.relu(self.hidden_layer(x))\n",
    "        x = F.softmax(self.output_layer(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "def get_accuracy(pred_arr,original_arr):\n",
    "    pred_arr = pred_arr.detach().numpy()\n",
    "    original_arr = original_arr.numpy()\n",
    "    final_pred= []\n",
    "\n",
    "    for i in range(len(pred_arr)):\n",
    "        final_pred.append(np.argmax(pred_arr[i]))\n",
    "    final_pred = np.array(final_pred)\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(original_arr)):\n",
    "        if final_pred[i] == original_arr[i]:\n",
    "            count+=1\n",
    "    return count/len(final_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, optimizer, X_train, y_train, X_test, y_test, train_weight, test_weight, num_epochs):\n",
    "    train_loss=[]\n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "    test_tversky = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        #forward feed\n",
    "        output_train = model(X_train)\n",
    "\n",
    "        train_accuracy.append(get_accuracy(output_train, y_train))\n",
    "\n",
    "        #calculate the loss\n",
    "        loss = torch_tversky(output_train, y_train, train_weight)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #backward propagation: calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_test = model(X_test)\n",
    "            test_accuracy.append(get_accuracy(output_test, y_test))\n",
    "            test_tversky.append(output_test, y_test, test_weight)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.4f}, Train Accuracy: {sum(train_accuracy)/len(train_accuracy):.2f}, Test Accuracy: {sum(test_accuracy)/len(test_accuracy):.2f}\")\n",
    "\n",
    "    return train_loss, train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim  = 4\n",
    "output_dim = 3\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = PyTorch_NN(input_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "train_loss, train_accuracy, test_accuracy = train_network(model=model, optimizer=optimizer, criterion=criterion, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
