{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Edited by Sizhuo Li\n",
    "   \n",
    "   Author: Ankit Kariryaa, University of Bremen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from rasterio import windows\n",
    "import fiona                     # I/O vector data (shape, geojson, ...)\n",
    "import geopandas as gps\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import mapping, shape\n",
    "\n",
    "import numpy as np               # numerical array manipulation\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from itertools import product\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import sys\n",
    "from core.UNet import UNet\n",
    "from core.losses import tversky, accuracy, dice_coef, dice_loss, specificity, sensitivity\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo, image_normalize\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.split_frames import split_dataset\n",
    "from core.visualize import display_images\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/RasterAnalysis.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    " \n",
    "from config import RasterAnalysis\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import RasterAnalysis\n",
    "\n",
    "config = RasterAnalysis.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "OPTIMIZER = adaDelta\n",
    "model = load_model(config.trained_model_path, custom_objects={'tversky': tversky, 'dice_coef': dice_coef, 'dice_loss':dice_loss, 'accuracy':accuracy, 'specificity':specificity, 'sensitivity':sensitivity}, compile=False)\n",
    "model.compile(optimizer=OPTIMIZER, loss=tversky, metrics=[dice_coef, dice_loss, accuracy, specificity, sensitivity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to add results of a patch to the total results of a larger area. The operator could be min (useful if there are too many false positives), max (useful for tackle false negatives)\n",
    "def addTOResult(res, prediction, row, col, he, wi, operator = 'MAX'):\n",
    "    currValue = res[row:row+he, col:col+wi]\n",
    "    newPredictions = prediction[:he, :wi]\n",
    "# IMPORTANT: MIN can't be used as long as the mask is initialed with 0!!!!! If you want to use MIN initial the mask with -1 and handle the case of default value(-1) separately.\n",
    "    if operator == 'MIN': # Takes the min of current prediction and new prediction for each pixel\n",
    "        currValue [currValue == -1] = 1 #Replace -1 with 1 in case of MIN\n",
    "        resultant = np.minimum(currValue, newPredictions) \n",
    "    elif operator == 'MAX':\n",
    "        resultant = np.maximum(currValue, newPredictions)\n",
    "    else: #operator == 'REPLACE':\n",
    "        resultant = newPredictions    \n",
    "# Alternative approach; Lets assume that quality of prediction is better in the centre of the image than on the edges\n",
    "# We use numbers from 1-5 to denote the quality, where 5 is the best and 1 is the worst.In that case, the best result would be to take into quality of prediction based upon position in account\n",
    "# So for merge with stride of 0.5, for eg. [12345432100000] AND [00000123454321], should be [1234543454321] instead of [1234543214321] that you will currently get. \n",
    "# However, in case the values are strecthed before hand this problem will be minimized\n",
    "    res[row:row+he, col:col+wi] =  resultant\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that actually makes the predictions\n",
    "def predict_using_model(model, batch, batch_pos, mask, operator):\n",
    "    tm = np.stack(batch, axis = 0)\n",
    "    prediction = model.predict(tm)\n",
    "    for i in range(len(batch_pos)):\n",
    "        (col, row, wi, he) = batch_pos[i]\n",
    "        p = np.squeeze(prediction[i], axis = -1)\n",
    "        # Instead of replacing the current values with new values, use the user specified operator (MIN,MAX,REPLACE)\n",
    "        mask = addTOResult(mask, p, row, col, he, wi, operator)\n",
    "    return mask\n",
    "    \n",
    "\n",
    "def detect_tree(ndvi_img, pan_img, width=256, height=256, stride = 128, normalize=True):\n",
    "    assert ndvi_img.meta['width'] == pan_img.meta['width'] and ndvi_img.meta['height'] == pan_img.meta['height']\n",
    "    nols, nrows = ndvi_img.meta['width'], ndvi_img.meta['height']\n",
    "    meta = ndvi_img.meta.copy()\n",
    "    if 'float' not in meta['dtype']: #The prediction is a float so we keep it as float to be consistent with the prediction. \n",
    "        meta['dtype'] = np.float32\n",
    "    offsets = product(range(0, nols, stride), range(0, nrows, stride))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "#     print(nrows, nols)\n",
    "\n",
    "    mask = np.zeros((nrows, nols), dtype=meta['dtype'])\n",
    "\n",
    "#     mask = mask -1 # Note: The initial mask is initialized with -1 instead of zero to handle the MIN case (see addToResult)\n",
    "    batch = []\n",
    "    batch_pos = [ ]\n",
    "    for col_off, row_off in  tqdm(offsets):\n",
    "        window =windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ndvi_img.transform)\n",
    "        patch = np.zeros((height, width, 2)) #Add zero padding in case of corner images\n",
    "        ndvi_sm = ndvi_img.read(window=window)\n",
    "        pan_sm = pan_img.read(window=window)\n",
    "        temp_im = np.stack((ndvi_sm, pan_sm), axis = -1)\n",
    "        temp_im = np.squeeze(temp_im)\n",
    "        \n",
    "        if normalize:\n",
    "            temp_im = image_normalize(temp_im, axis=(0,1)) # Normalize the image along the width and height i.e. independently per channel\n",
    "            \n",
    "        patch[:window.height, :window.width] = temp_im\n",
    "        batch.append(patch)\n",
    "        batch_pos.append((window.col_off, window.row_off, window.width, window.height))\n",
    "        if (len(batch) == config.BATCH_SIZE):\n",
    "            mask = predict_using_model(model, batch, batch_pos, mask, 'MAX')\n",
    "            batch = []\n",
    "            batch_pos = []\n",
    "            \n",
    "    # To handle the edge of images as the image size may not be divisible by n complete batches and few frames on the edge may be left.\n",
    "    if batch:\n",
    "        mask = predict_using_model(model, batch, batch_pos, mask, 'MAX')\n",
    "        batch = []\n",
    "        batch_pos = []\n",
    "\n",
    "    return(mask, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {'id': 'str', 'canopy': 'float:15.2',},\n",
    "    }\n",
    "\n",
    "def drawPolygons(polygons, shape):\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    for polygon in polygons:\n",
    "        xy = [(point[1], point[0]) for point in polygon]\n",
    "        draw.polygon(xy=xy, outline=255, fill=255)\n",
    "    mask = np.array(mask)#, dtype=bool)   \n",
    "    return(mask)\n",
    "\n",
    "def transformToXY(polygons, transform):\n",
    "    tp = []\n",
    "    for polygon in polygons:\n",
    "        rows, cols = zip(*polygon)\n",
    "        x,y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tp.append(list(zip(x,y)))\n",
    "    return (tp)\n",
    "\n",
    "def createShapefileObject(polygons, meta, wfile):\n",
    "    with fiona.open(wfile, 'w', crs=meta.get('crs').to_dict(), driver='ESRI Shapefile', schema=schema) as sink:\n",
    "        for idx, mp in enumerate(polygons):\n",
    "            try:\n",
    "#                 poly = Polygon(poly)\n",
    "    #             assert mp.is_valid\n",
    "    #             assert mp.geom_type == 'Polygon'\n",
    "                sink.write({\n",
    "                    'geometry': mapping(mp),\n",
    "                    'properties': {'id': str(idx), 'canopy': mp.area},\n",
    "                })\n",
    "            except:\n",
    "                print(\"An exception occurred in createShapefileObject; Polygon must have more than 2 points\")\n",
    "#                 print(mp)\n",
    "\n",
    "# Generate a mask with polygons\n",
    "def transformContoursToXY(contours, transform = None):\n",
    "    tp = []\n",
    "    for cnt in contours:\n",
    "        pl = cnt[:, 0, :]\n",
    "        cols, rows = zip(*pl)\n",
    "        x,y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tl = [list(i) for i in zip(x, y)]\n",
    "        tp.append(tl)\n",
    "    return (tp)\n",
    "\n",
    "\n",
    "def mask_to_polygons(maskF, transform):\n",
    "    # first, find contours with cv2: it's much faster than shapely\n",
    "    th = 0.5\n",
    "    mask = maskF.copy()\n",
    "    mask[mask < th] = 0\n",
    "    mask[mask >= th] = 1\n",
    "    mask = ((mask) * 255).astype(np.uint8)\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    #Convert contours from image coordinate to xy coordinate\n",
    "    contours = transformContoursToXY(contours, transform)\n",
    "    if not contours: #TODO: Raise an error maybe\n",
    "        print('Warning: No contours/polygons detected!!')\n",
    "        return [Polygon()]\n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(contours[idx])\n",
    "\n",
    "    # create actual polygons filtering by area (removes artifacts)\n",
    "    all_polygons = []\n",
    "\n",
    "    for idx, cnt in enumerate(contours):\n",
    "        if idx not in child_contours: #and cv2.contourArea(cnt) >= min_area: #Do we need to check for min_area??\n",
    "            try:\n",
    "                poly = Polygon(\n",
    "                    shell=cnt,\n",
    "                    holes=[c for c in cnt_children.get(idx, [])])\n",
    "                           #if cv2.contourArea(c) >= min_area]) #Do we need to check for min_area??\n",
    "                all_polygons.append(poly)\n",
    "            except:\n",
    "                pass\n",
    "#                 print(\"An exception occurred in createShapefileObject; Polygon must have more than 2 points\")\n",
    "    print(len(all_polygons))\n",
    "    return(all_polygons)\n",
    "\n",
    "def create_contours_shapefile(mask, meta, out_fn):\n",
    "    res = mask_to_polygons(mask, meta['transform'])\n",
    "#     res = transformToXY(contours, meta['transform'])\n",
    "    createShapefileObject(res, meta, out_fn)\n",
    "\n",
    "\n",
    "def writeMaskToDisk(detected_mask, detected_meta, wp, write_as_type = 'uint8', th = 0.5, create_countors = False):\n",
    "    # Convert to correct required before writing\n",
    "    if 'float' in str(detected_meta['dtype']) and 'int' in write_as_type:\n",
    "        print(f'Converting prediction from {detected_meta[\"dtype\"]} to {write_as_type}, using threshold of {th}')\n",
    "        detected_mask[detected_mask<th]=0\n",
    "        detected_mask[detected_mask>=th]=1\n",
    "        detected_mask = detected_mask.astype(write_as_type)\n",
    "        detected_meta['dtype'] =  write_as_type\n",
    "        \n",
    "    with rasterio.open(wp, 'w', **detected_meta) as outds:\n",
    "        outds.write(detected_mask, 1)\n",
    "    if create_countors:\n",
    "        wp = wp.replace(image_type, output_shapefile_type)\n",
    "        create_contours_shapefile(detected_mask, detected_meta, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict trees in the all the files in the input image dir\n",
    "# Depending upon the available RAM, images may not to be split before running this cell.\n",
    "# Use the Auxiliary-2-SplitRasterToAnalyse if the images are too big to be analysed in memory.\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(config.input_image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(config.input_image_type) and file.startswith(config.ndvi_fn_st):\n",
    "             all_files.append((os.path.join(root, file), file))\n",
    "# print(all_files)\n",
    "for fullPath, filename in all_files:\n",
    "    outputFile = os.path.join(config.output_dir, filename.replace(config.ndvi_fn_st, config.output_prefix) )\n",
    "    if not os.path.isfile(outputFile) or config.overwrite_analysed_files: \n",
    "        with rasterio.open(fullPath) as ndvi:\n",
    "            with rasterio.open(fullPath.replace(config.ndvi_fn_st, config.pan_fn_st)) as pan:\n",
    "                print(fullPath)\n",
    "                detectedMask, detectedMeta = detect_tree(ndvi, pan, width = config.WIDTH, height = config.HEIGHT, stride = config.STRIDE) # WIDTH and HEIGHT should be the same and in this case Stride is 50 % width\n",
    "                #Write the mask to file\n",
    "                writeMaskToDisk(detectedMask, detectedMeta, outputFile, write_as_type = config.output_dtype, th = 0.5, create_countors = False)                \n",
    "    else:\n",
    "        print('File already analysed!', fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extracted image\n",
    "sampleImage = ''\n",
    "fn = os.path.join(config.output_dir, config.output_prefix + sampleImage )\n",
    "predicted_img = rasterio.open(fn)\n",
    "p = predicted_img.read()\n",
    "np.unique(p, return_counts=True)\n",
    "plt.imshow(p[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
