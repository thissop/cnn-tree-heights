{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Author: Ankit Kariryaa, University of Bremen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np               # numerical array manipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from PIL import Image\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import mapping, shape\n",
    "import fiona\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.UNet import UNet\n",
    "from core.losses import tversky, accuracy, dice_coef, dice_loss, specificity, sensitivity\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.split_frames import split_dataset\n",
    "from core.visualize import display_images\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data related variables used in the notebook\n",
    "\n",
    "# For reading the ndvi, pan and annotated images generated in the step - 1\n",
    "base_dir = ''\n",
    "image_type = '.png'\n",
    "ndvi_fn = 'ndvi'\n",
    "pan_fn = 'pan'\n",
    "annotation_fn = 'annotation'\n",
    "weight_fn = 'boundary'\n",
    "\n",
    "# For testing, images are divided into sequential patches\n",
    "patch_generation_stratergy = 'sequential'\n",
    "patch_size = (256,256,4)\n",
    "BATCH_SIZE = 8 # Model is evaluated in batches; See https://keras.io/models/model/#evaluate\n",
    "\n",
    "# # When stratergy == sequential\n",
    "step_size = (256,256)\n",
    "\n",
    "\n",
    "# The data has four channels\n",
    "# The order is [NDVI, PAN, ANNOTATION, WEIGHT]\n",
    "input_shape = (256,256,2)\n",
    "input_image_channel = [0,1]\n",
    "input_label_channel = [2]\n",
    "input_weight_channel = [3]\n",
    "\n",
    "OPTIMIZER = adaDelta \n",
    "LOSS = tversky\n",
    "\n",
    "#Only for the name of the model in the very end\n",
    "OPTIMIZER_NAME = 'adaDelta'\n",
    "LOSS_NAME = 'weightmap_tversky'\n",
    "\n",
    "modelToEvaluate =''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File path for final report \n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = input_image_channel + input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '')\n",
    "\n",
    "evaluation_report_path = model_path = './'\n",
    "if not os.path.exists(evaluation_report_path):\n",
    "    os.makedirs(evaluation_report_path)\n",
    "evaluation_report_filename = os.path.join(evaluation_report_path,'evaluation_per_pixel{}_{}.csv'.format(timestr,chs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all images/frames into memory\n",
    "frames = []\n",
    "\n",
    "all_files = os.listdir(base_dir)\n",
    "all_files_ndvi = [fn for fn in all_files if fn.startswith(ndvi_fn) and fn.endswith(image_type)]\n",
    "len(all_files_ndvi)\n",
    "#dtype = {'F': np.float32, 'L': np.uint8}[pil_img.mode]\n",
    "for i, fn in enumerate(all_files_ndvi):\n",
    "    ndvi_img = rasterio.open(os.path.join(base_dir, fn))\n",
    "    pan_img = rasterio.open(os.path.join(base_dir, fn.replace(ndvi_fn,pan_fn)))\n",
    "    read_ndvi_img = ndvi_img.read()\n",
    "    read_pan_img = pan_img.read()\n",
    "    comb_img = np.concatenate((read_ndvi_img, read_pan_img), axis=0)\n",
    "    comb_img = np.transpose(comb_img, axes=(1,2,0)) #Channel at the end\n",
    "    annotation_im = Image.open(os.path.join(base_dir, fn.replace(ndvi_fn,annotation_fn)))\n",
    "    annotation = np.array(annotation_im)\n",
    "    weight_im = Image.open(os.path.join(base_dir, fn.replace(ndvi_fn,weight_fn)))\n",
    "    weight = np.array(weight_im)\n",
    "    f = FrameInfo(comb_img, annotation, weight)\n",
    "    frames.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing on all frames. All sequential frames are kept in memory and this may create memory related errors in some cases. \n",
    "testing_frames  = list(range(len(frames)))\n",
    "\n",
    "annotation_channels = input_label_channel + input_weight_channel\n",
    "test_generator = DataGenerator(input_image_channel, patch_size, testing_frames, frames, annotation_channels)\n",
    "\n",
    "# Sequential generate all patches from the all frames\n",
    "test_patches = test_generator.all_sequential_patches(step_size)\n",
    "print('Total patches to evaluate the model on: ' + str(len(test_patches[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the some of the test images\n",
    "numberOfImagesToDisplay = 10\n",
    "\n",
    "train_images, real_label = test_patches[0][:numberOfImagesToDisplay], test_patches[1][:numberOfImagesToDisplay]\n",
    "display_images(np.concatenate((train_images,real_label), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "def evaluate_model(model_path, evaluation_report_filename):\n",
    "    print(model_path, evaluation_report_filename)\n",
    "    model = load_model(model_path, custom_objects={'tversky': tversky, 'dice_coef': dice_coef, 'dice_loss':dice_loss, 'accuracy':accuracy , 'specificity': specificity, 'sensitivity':sensitivity}, compile=False)\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_coef, dice_loss, accuracy, specificity, sensitivity])\n",
    "    print('Evaluating model now!')\n",
    "    ev = model.evaluate(x=test_patches[0], y=test_patches[1],  verbose=1, use_multiprocessing=True)\n",
    "    report  = dict(zip(model.metrics_names, ev))\n",
    "    report['model_path'] =  model_path\n",
    "    report['test_frame_dir']= base_dir\n",
    "    report['total_patch_count']= len(test_patches[0])\n",
    "    return report\n",
    "\n",
    "report = evaluate_model(modelToEvaluate, evaluation_report_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the model predictions!\n",
    "model = load_model(modelToEvaluate, custom_objects={'tversky': tversky, 'dice_coef': dice_coef, 'dice_loss':dice_loss, 'accuracy':accuracy , 'specificity': specificity, 'sensitivity':sensitivity}, compile=False)\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_coef, dice_loss, accuracy, specificity, sensitivity])\n",
    "predictions = []\n",
    "for tp in test_patches[0]:\n",
    "    tpx = np.expand_dims(tp, axis=0)\n",
    "    modelpredtictions = model.predict(tpx, batch_size=BATCH_SIZE)\n",
    "    predictions.append(np.squeeze(modelpredtictions, axis = 0))\n",
    "\n",
    "display_images(np.concatenate((test_patches[0], test_patches[1][...,[0]], predictions), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Contours from image to world coordinates  \n",
    "def transform_contours_to_xy(contours, transform):\n",
    "    tp = []\n",
    "    for cnt in contours:\n",
    "        pl = cnt[:, 0, :]\n",
    "        cols, rows = zip(*pl)\n",
    "        x,y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tl = [list(i) for i in zip(x, y)]\n",
    "        tp.append(tl)\n",
    "    return (tp)\n",
    "\n",
    "def mask_to_polygons(mask, transform, th = 0.5):\n",
    "    # first, find contours with cv2: it's much faster than shapely and returns hierarchy\n",
    "    mask[mask < th] = 0\n",
    "    mask[mask >= th] = 1\n",
    "    mask = ((mask) * 255).astype(np.uint8)\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #Convert contours from image coordinate to xy coordinate (world coordinates)\n",
    "    contours = transform_contours_to_xy(contours, transform)\n",
    "\n",
    "    if not contours: #TODO: Raise an error maybe\n",
    "        print('Warning: No contours/polygons detected!!')\n",
    "        return [Polygon()]#[Polygon()]\n",
    "    \n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(contours[idx])\n",
    "    # create actual polygons filtering by area/hole (removes artifacts)\n",
    "    all_polygons = []\n",
    "    for idx, cnt in enumerate(contours):\n",
    "        if idx not in child_contours: #and cv2.contourArea(cnt) >= min_area: #Do we need to check for min_area??\n",
    "            try:\n",
    "                poly = Polygon(\n",
    "                    shell=cnt,\n",
    "                    holes=[c for c in cnt_children.get(idx, [])])\n",
    "                           #if cv2.contourArea(c) >= min_area]) #Do we need to check for min_area??\n",
    "                all_polygons.append(poly)\n",
    "            except Exception as e: \n",
    "#                 print(e)\n",
    "                pass\n",
    "#     print(len(all_polygons))\n",
    "    return(all_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj    \n",
    "import shapely\n",
    "import shapely.ops as ops\n",
    "\n",
    "def transform_to_meter_coordinate_system(geom):\n",
    "    # TODO: Remove the hard coded values\n",
    "    project = pyproj.Transformer.from_proj(\n",
    "        pyproj.Proj(init='epsg:4326'), # source coordinate system\n",
    "        pyproj.Proj(init='epsg:3857')) # destination coordinate system\n",
    "    gt = ops.transform(project.transform, geom)  # apply projection\n",
    "    return gt\n",
    "\n",
    "def ha_area(ha_polygons):\n",
    "    ts = 0\n",
    "    ha_polygons_meter = [transform_to_meter_coordinate_system(p) for p in ha_polygons]\n",
    "    for p in ha_polygons_meter:\n",
    "        ts += p.area\n",
    "    return ts\n",
    "\n",
    "def ha_area_from_mask(mask, th = 0.5):\n",
    "    mask[mask < th] = 0\n",
    "    mask[mask >= th] = 1\n",
    "#     totalMaskArea = 256*256/4\n",
    "    canopyArea = mask.sum()/4 # Divide by 4, since we use a resolution of 50cm/pixel\n",
    "    return canopyArea\n",
    "\n",
    "# TODO: Remove the need for the a tiff file for transformation\n",
    "with rasterio.open('path to a .tif') as raster_image:\n",
    "#     print(raster_image.meta)\n",
    "    transform = raster_image.meta['transform']\n",
    "print(transform)\n",
    "\n",
    "ha_prediction_polygons = []\n",
    "ha_label_polygons = []\n",
    "    \n",
    "ha_prediction_canopy_area = []\n",
    "ha_label_canopy_area = []\n",
    "\n",
    "for em, pred in enumerate(predictions):\n",
    "    ap = mask_to_polygons(pred, transform )\n",
    "    ha_prediction_polygons.append(ap)\n",
    "    ha_prediction_canopy_area.append(ha_area_from_mask(pred))\n",
    "\n",
    "for lb in test_patches[1][...,[0]]:\n",
    "    ap = mask_to_polygons(lb, transform)\n",
    "    ha_label_polygons.append(ap)\n",
    "    ha_label_canopy_area.append(ha_area_from_mask(lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_prediction_polygons_count = [len(hp) for hp in ha_prediction_polygons]\n",
    "ha_label_polygons_count = [len(hp) for hp in ha_label_polygons]\n",
    "\n",
    "#Alternate method to calcualte canopy area as a sum of area of trees\n",
    "# print('To calculate the area we convert the polygons to a coordinate system where unit is meters. This process is time consuming.')\n",
    "# ha_prediction_canopy_area = list(map(ha_area, ha_prediction_polygons))\n",
    "# ha_label_canopy_area = list(map(ha_area, ha_label_polygons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "print(len(ha_prediction_polygons_count))\n",
    "ha_count_correlation = pearsonr(ha_prediction_polygons_count, ha_label_polygons_count)\n",
    "ha_area_correlation = pearsonr(ha_prediction_canopy_area, ha_label_canopy_area)\n",
    "\n",
    "print('Count correlation:' + str(ha_count_correlation))\n",
    "print('Area correlation:' + str(ha_area_correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the final report\n",
    "\n",
    "report['count_correlation'] =  ha_count_correlation[0]\n",
    "report['count_correlation_tvalue'] =  ha_count_correlation[1]\n",
    "report['area_correlation'] = ha_area_correlation[0]\n",
    "report['area_correlation_tvalue'] =  ha_area_correlation[1]\n",
    "\n",
    "print(report)\n",
    "\n",
    "tdf = pd.DataFrame(report, index=[0])    \n",
    "# print(tdf.columns)\n",
    "col_beginning = ['model_path','test_frame_dir', 'total_patch_count', 'accuracy', 'sensitivity']\n",
    "col_rest = [x for x in tdf.columns.tolist() if x not in col_beginning]\n",
    "cols = col_beginning + col_rest\n",
    "tdf = tdf[cols]\n",
    "tdf.to_csv(evaluation_report_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ha_label_polygons_count,ha_prediction_polygons_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ha_label_canopy_area, ha_prediction_canopy_area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
