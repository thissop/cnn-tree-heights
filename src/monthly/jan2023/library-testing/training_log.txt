10
10
10
10
Reading train-test split from file
training_frames [9, 6, 7, 4, 8, 3]
validation_frames [5, 2]
testing_frames [0, 1]


[8, 256, 256, 2]


Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 Input (InputLayer)             [(None, 256, 256, 2  0           []                               
                                )]                                                                
                                                                                                  
 conv2d (Conv2D)                (None, 256, 256, 64  1216        ['Input[0][0]']                  
                                )                                                                 
                                                                                                  
 conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 
                                )                                                                 
                                                                                                  
 batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               
 alization)                     )                                                                 
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['batch_normalization[0][0]']    
                                )                                                                 
                                                                                                  
 conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          
                                8)                                                                
                                                                                                  
 conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               
                                8)                                                                
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               
 rmalization)                   8)                                                                
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['batch_normalization_1[0][0]']  
                                                                                                  
 conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        
                                                                                                  
 conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['batch_normalization_2[0][0]']  
                                                                                                  
 conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        
                                                                                                  
 conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['batch_normalization_3[0][0]']  
                                                                                                  
 conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        
                                )                                                                 
                                                                                                  
 conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['conv2d_8[0][0]']               
                                )                                                                 
                                                                                                  
 up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['conv2d_9[0][0]']               
                                )                                                                 
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 32, 32, 1024  4096       ['up_sampling2d[0][0]']          
 rmalization)                   )                                                                 
                                                                                                  
 concatenate (Concatenate)      (None, 32, 32, 1536  0           ['batch_normalization_4[0][0]',  
                                )                                 'batch_normalization_3[0][0]']  
                                                                                                  
 conv2d_10 (Conv2D)             (None, 32, 32, 512)  7078400     ['concatenate[0][0]']            
                                                                                                  
 conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_10[0][0]']              
                                                                                                  
 up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_11[0][0]']              
                                                                                                  
 batch_normalization_5 (BatchNo  (None, 64, 64, 512)  2048       ['up_sampling2d_1[0][0]']        
 rmalization)                                                                                     
                                                                                                  
 concatenate_1 (Concatenate)    (None, 64, 64, 768)  0           ['batch_normalization_5[0][0]',  
                                                                  'batch_normalization_2[0][0]']  
                                                                                                  
 conv2d_12 (Conv2D)             (None, 64, 64, 256)  1769728     ['concatenate_1[0][0]']          
                                                                                                  
 conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_12[0][0]']              
                                                                                                  
 up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_13[0][0]']              
                                6)                                                                
                                                                                                  
 batch_normalization_6 (BatchNo  (None, 128, 128, 25  1024       ['up_sampling2d_2[0][0]']        
 rmalization)                   6)                                                                
                                                                                                  
 concatenate_2 (Concatenate)    (None, 128, 128, 38  0           ['batch_normalization_6[0][0]',  
                                4)                                'batch_normalization_1[0][0]']  
                                                                                                  
 conv2d_14 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_2[0][0]']          
                                8)                                                                
                                                                                                  
 conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_14[0][0]']              
                                8)                                                                
                                                                                                  
 up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_15[0][0]']              
                                8)                                                                
                                                                                                  
 batch_normalization_7 (BatchNo  (None, 256, 256, 12  512        ['up_sampling2d_3[0][0]']        
 rmalization)                   8)                                                                
                                                                                                  
 concatenate_3 (Concatenate)    (None, 256, 256, 19  0           ['batch_normalization_7[0][0]',  
                                2)                                'batch_normalization[0][0]']    
                                                                                                  
 conv2d_16 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_3[0][0]']          
                                )                                                                 
                                                                                                  
 conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_16[0][0]']              
                                )                                                                 
                                                                                                  
 conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['conv2d_17[0][0]']              
                                                                                                  
==================================================================================================
Total params: 31,389,889
Trainable params: 31,384,129
Non-trainable params: 5,760
__________________________________________________________________________________________________
 1/50 [..............................] - ETA: 5:08 - loss: 0.9694 - dice_coef: 0.0097 - dice_loss: 0.9903 - specificity: 0.4795 - sensitivity: 0.4834 - accuracy: 0.4796 2/50 [>.............................] - ETA: 2:43 - loss: 0.9546 - dice_coef: 0.0130 - dice_loss: 0.9870 - specificity: 0.4767 - sensitivity: 0.5190 - accuracy: 0.4777 3/50 [>.............................] - ETA: 2:40 - loss: 0.9443 - dice_coef: 0.0144 - dice_loss: 0.9856 - specificity: 0.4720 - sensitivity: 0.5395 - accuracy: 0.4737 4/50 [=>............................] - ETA: 2:32 - loss: 0.9365 - dice_coef: 0.0166 - dice_loss: 0.9834 - specificity: 0.5044 - sensitivity: 0.5237 - accuracy: 0.5045 5/50 [==>...........................] - ETA: 2:27 - loss: 0.9324 - dice_coef: 0.0171 - dice_loss: 0.9829 - specificity: 0.5183 - sensitivity: 0.5200 - accuracy: 0.5181 6/50 [==>...........................] - ETA: 2:24 - loss: 0.9207 - dice_coef: 0.0189 - dice_loss: 0.9811 - specificity: 0.5519 - sensitivity: 0.4992 - accuracy: 0.5493 7/50 [===>..........................] - ETA: 2:23 - loss: 0.9127 - dice_coef: 0.0196 - dice_loss: 0.9804 - specificity: 0.5651 - sensitivity: 0.4990 - accuracy: 0.5620 8/50 [===>..........................] - ETA: 2:20 - loss: 0.9157 - dice_coef: 0.0186 - dice_loss: 0.9814 - specificity: 0.5883 - sensitivity: 0.4786 - accuracy: 0.5843 9/50 [====>.........................] - ETA: 2:16 - loss: 0.9100 - dice_coef: 0.0188 - dice_loss: 0.9812 - specificity: 0.6035 - sensitivity: 0.4681 - accuracy: 0.598410/50 [=====>........................] - ETA: 2:12 - loss: 0.9029 - dice_coef: 0.0190 - dice_loss: 0.9810 - specificity: 0.6198 - sensitivity: 0.4515 - accuracy: 0.612711/50 [=====>........................] - ETA: 2:09 - loss: 0.8955 - dice_coef: 0.0193 - dice_loss: 0.9807 - specificity: 0.6333 - sensitivity: 0.4446 - accuracy: 0.625112/50 [======>.......................] - ETA: 2:08 - loss: 0.8885 - dice_coef: 0.0192 - dice_loss: 0.9808 - specificity: 0.6452 - sensitivity: 0.4382 - accuracy: 0.636213/50 [======>.......................] - ETA: 2:04 - loss: 0.8875 - dice_coef: 0.0187 - dice_loss: 0.9813 - specificity: 0.6516 - sensitivity: 0.4323 - accuracy: 0.642314/50 [=======>......................] - ETA: 2:01 - loss: 0.8840 - dice_coef: 0.0185 - dice_loss: 0.9815 - specificity: 0.6621 - sensitivity: 0.4249 - accuracy: 0.652015/50 [========>.....................] - ETA: 1:58 - loss: 0.8825 - dice_coef: 0.0183 - dice_loss: 0.9817 - specificity: 0.6698 - sensitivity: 0.4243 - accuracy: 0.659616/50 [========>.....................] - ETA: 1:54 - loss: 0.8821 - dice_coef: 0.0179 - dice_loss: 0.9821 - specificity: 0.6794 - sensitivity: 0.4162 - accuracy: 0.668617/50 [=========>....................] - ETA: 1:51 - loss: 0.8825 - dice_coef: 0.0174 - dice_loss: 0.9826 - specificity: 0.6865 - sensitivity: 0.4115 - accuracy: 0.675718/50 [=========>....................] - ETA: 1:48 - loss: 0.8815 - dice_coef: 0.0171 - dice_loss: 0.9829 - specificity: 0.6923 - sensitivity: 0.4065 - accuracy: 0.681219/50 [==========>...................] - ETA: 1:45 - loss: 0.8847 - dice_coef: 0.0166 - dice_loss: 0.9834 - specificity: 0.6948 - sensitivity: 0.3989 - accuracy: 0.683720/50 [===========>..................] - ETA: 1:41 - loss: 0.8816 - dice_coef: 0.0166 - dice_loss: 0.9834 - specificity: 0.6986 - sensitivity: 0.4048 - accuracy: 0.687721/50 [===========>..................] - ETA: 1:37 - loss: 0.8817 - dice_coef: 0.0162 - dice_loss: 0.9838 - specificity: 0.7062 - sensitivity: 0.3965 - accuracy: 0.694822/50 [============>.................] - ETA: 1:34 - loss: 0.8821 - dice_coef: 0.0159 - dice_loss: 0.9841 - specificity: 0.7132 - sensitivity: 0.3850 - accuracy: 0.700823/50 [============>.................] - ETA: 1:31 - loss: 0.8806 - dice_coef: 0.0157 - dice_loss: 0.9843 - specificity: 0.7200 - sensitivity: 0.3797 - accuracy: 0.707024/50 [=============>................] - ETA: 1:27 - loss: 0.8758 - dice_coef: 0.0157 - dice_loss: 0.9843 - specificity: 0.7253 - sensitivity: 0.3777 - accuracy: 0.711925/50 [==============>...............] - ETA: 1:24 - loss: 0.8748 - dice_coef: 0.0155 - dice_loss: 0.9845 - specificity: 0.7296 - sensitivity: 0.3737 - accuracy: 0.716026/50 [==============>...............] - ETA: 1:20 - loss: 0.8765 - dice_coef: 0.0153 - dice_loss: 0.9847 - specificity: 0.7335 - sensitivity: 0.3664 - accuracy: 0.719527/50 [===============>..............] - ETA: 1:17 - loss: 0.8766 - dice_coef: 0.0152 - dice_loss: 0.9848 - specificity: 0.7364 - sensitivity: 0.3661 - accuracy: 0.722428/50 [===============>..............] - ETA: 1:14 - loss: 0.8762 - dice_coef: 0.0152 - dice_loss: 0.9848 - specificity: 0.7387 - sensitivity: 0.3632 - accuracy: 0.724429/50 [================>.............] - ETA: 1:10 - loss: 0.8762 - dice_coef: 0.0150 - dice_loss: 0.9850 - specificity: 0.7421 - sensitivity: 0.3604 - accuracy: 0.727730/50 [=================>............] - ETA: 1:07 - loss: 0.8749 - dice_coef: 0.0150 - dice_loss: 0.9850 - specificity: 0.7454 - sensitivity: 0.3607 - accuracy: 0.731031/50 [=================>............] - ETA: 1:03 - loss: 0.8738 - dice_coef: 0.0148 - dice_loss: 0.9852 - specificity: 0.7501 - sensitivity: 0.3553 - accuracy: 0.735532/50 [==================>...........] - ETA: 1:00 - loss: 0.8744 - dice_coef: 0.0147 - dice_loss: 0.9853 - specificity: 0.7540 - sensitivity: 0.3506 - accuracy: 0.739033/50 [==================>...........] - ETA: 57s - loss: 0.8717 - dice_coef: 0.0148 - dice_loss: 0.9852 - specificity: 0.7567 - sensitivity: 0.3494 - accuracy: 0.7416 34/50 [===================>..........] - ETA: 53s - loss: 0.8724 - dice_coef: 0.0148 - dice_loss: 0.9852 - specificity: 0.7602 - sensitivity: 0.3454 - accuracy: 0.745135/50 [====================>.........] - ETA: 50s - loss: 0.8709 - dice_coef: 0.0151 - dice_loss: 0.9849 - specificity: 0.7620 - sensitivity: 0.3463 - accuracy: 0.746836/50 [====================>.........] - ETA: 47s - loss: 0.8710 - dice_coef: 0.0152 - dice_loss: 0.9848 - specificity: 0.7641 - sensitivity: 0.3443 - accuracy: 0.748837/50 [=====================>........] - ETA: 43s - loss: 0.8697 - dice_coef: 0.0154 - dice_loss: 0.9846 - specificity: 0.7657 - sensitivity: 0.3451 - accuracy: 0.750438/50 [=====================>........] - ETA: 40s - loss: 0.8706 - dice_coef: 0.0153 - dice_loss: 0.9847 - specificity: 0.7679 - sensitivity: 0.3453 - accuracy: 0.752739/50 [======================>.......] - ETA: 36s - loss: 0.8694 - dice_coef: 0.0153 - dice_loss: 0.9847 - specificity: 0.7703 - sensitivity: 0.3428 - accuracy: 0.754940/50 [=======================>......] - ETA: 33s - loss: 0.8689 - dice_coef: 0.0155 - dice_loss: 0.9845 - specificity: 0.7719 - sensitivity: 0.3427 - accuracy: 0.756441/50 [=======================>......] - ETA: 30s - loss: 0.8689 - dice_coef: 0.0158 - dice_loss: 0.9842 - specificity: 0.7727 - sensitivity: 0.3427 - accuracy: 0.757342/50 [========================>.....] - ETA: 26s - loss: 0.8693 - dice_coef: 0.0157 - dice_loss: 0.9843 - specificity: 0.7748 - sensitivity: 0.3378 - accuracy: 0.758843/50 [========================>.....] - ETA: 23s - loss: 0.8706 - dice_coef: 0.0156 - dice_loss: 0.9844 - specificity: 0.7761 - sensitivity: 0.3351 - accuracy: 0.760144/50 [=========================>....] - ETA: 20s - loss: 0.8713 - dice_coef: 0.0156 - dice_loss: 0.9844 - specificity: 0.7776 - sensitivity: 0.3335 - accuracy: 0.761745/50 [==========================>...] - ETA: 16s - loss: 0.8714 - dice_coef: 0.0154 - dice_loss: 0.9846 - specificity: 0.7795 - sensitivity: 0.3297 - accuracy: 0.763246/50 [==========================>...] - ETA: 13s - loss: 0.8720 - dice_coef: 0.0154 - dice_loss: 0.9846 - specificity: 0.7805 - sensitivity: 0.3308 - accuracy: 0.764447/50 [===========================>..] - ETA: 10s - loss: 0.8725 - dice_coef: 0.0152 - dice_loss: 0.9848 - specificity: 0.7829 - sensitivity: 0.3281 - accuracy: 0.766848/50 [===========================>..] - ETA: 6s - loss: 0.8731 - dice_coef: 0.0150 - dice_loss: 0.9850 - specificity: 0.7853 - sensitivity: 0.3241 - accuracy: 0.7690 49/50 [============================>.] - ETA: 3s - loss: 0.8751 - dice_coef: 0.0148 - dice_loss: 0.9852 - specificity: 0.7873 - sensitivity: 0.3192 - accuracy: 0.770950/50 [==============================] - ETA: 0s - loss: 0.8758 - dice_coef: 0.0147 - dice_loss: 0.9853 - specificity: 0.7891 - sensitivity: 0.3189 - accuracy: 0.7728
Epoch 1: val_loss improved from inf to 0.89798, saving model to /ar1/PROJ/fjuhsd/personal/thaddaeus/other/cnn-heights/output/saved_models/UNet/trees_20230127-1750_AdaDelta_weightmap_tversky_012_256.h5
50/50 [==============================] - 174s 3s/step - loss: 0.8758 - dice_coef: 0.0147 - dice_loss: 0.9853 - specificity: 0.7891 - sensitivity: 0.3189 - accuracy: 0.7728 - val_loss: 0.8980 - val_dice_coef: 0.0015 - val_dice_loss: 0.9985 - val_specificity: 0.9587 - val_sensitivity: 0.0413 - val_accuracy: 0.9700
time elapsed 174.7827913761139 (s)
