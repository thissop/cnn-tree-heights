{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "pyproj.datadir.set_data_dir('/home/fjuhsd/miniconda3/envs/cnnheights38/share/proj')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Overflow Answer\n",
    "\n",
    "Your installation of pyproj does not see the correct database. See https://pyproj4.github.io/pyproj/stable/gotchas.html#internal-proj-error-sqlite-error-on-select.\n",
    "\n",
    "This often happens if you start Jupyter in one environment and change the kernel. The link to PROJ database remains the same which may cause troubles.\n",
    "\n",
    "For example, let's assume that I have started Jupyter lab in geo_env environment and then switched kernel to development environment and got the error as you did.\n",
    "\n",
    "### My Notes\n",
    "\n",
    "- jupyter notebook pyproj.datadir.get_data_dir(): '/home/fjuhsd/miniconda3/share/proj'\n",
    "- python file pyproj.datadir.get_data_dir(): '/home/fjuhsd/miniconda3/envs/cnnheights38/share/proj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train-test split from file\n",
      "training_frames [9, 6, 7, 4, 8, 3]\n",
      "validation_frames [5, 2]\n",
      "testing_frames [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 16:13:19.015815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/fjuhsd/miniconda3/envs/cnnheights38/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adadelta.py:79: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/fjuhsd/miniconda3/envs/cnnheights38/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/fjuhsd/miniconda3/envs/cnnheights38/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/nadam.py:86: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/fjuhsd/miniconda3/envs/cnnheights38/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "2023-02-05 16:13:20.232871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 16:13:20.236076: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[8, 256, 256, 2]\n",
      "\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 256, 256, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  1216        ['Input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 1024  4096       ['up_sampling2d[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1536  0           ['batch_normalization_4[0][0]',  \n",
      "                                )                                 'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 512)  7078400     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 512)  2048       ['up_sampling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 768)  0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1769728     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_13[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 128, 128, 25  1024       ['up_sampling2d_2[0][0]']        \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 38  0           ['batch_normalization_6[0][0]',  \n",
      "                                4)                                'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_14[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_15[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 256, 256, 12  512        ['up_sampling2d_3[0][0]']        \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 19  0           ['batch_normalization_7[0][0]',  \n",
      "                                2)                                'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,389,889\n",
      "Trainable params: 31,384,129\n",
      "Non-trainable params: 5,760\n",
      "__________________________________________________________________________________________________\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8841 - dice_coef: 0.0227 - dice_loss: 0.9773 - specificity: 0.6987 - sensitivity: 0.3983 - accuracy: 0.6878\n",
      "Epoch 1: val_loss improved from inf to -0.23483, saving model to /ar1/PROJ/fjuhsd/personal/thaddaeus/other/cnn-heights/output/saved_models/UNet/trees_20230205-1613_AdaDelta_weightmap_tversky_012_256.h5\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.8841 - dice_coef: 0.0227 - dice_loss: 0.9773 - specificity: 0.6987 - sensitivity: 0.3983 - accuracy: 0.6878 - val_loss: -0.2348 - val_dice_coef: 0.0237 - val_dice_loss: 0.9763 - val_specificity: 0.5067 - val_sensitivity: 0.4932 - val_accuracy: 0.6807\n",
      "time elapsed 24.741766452789307 (s)\n"
     ]
    }
   ],
   "source": [
    "#NB_EPOCHS, MAX_TRAIN_STEPS\n",
    "import os\n",
    "from cnnheights.training import train_cnn\n",
    "from cnnheights.prediction import predict\n",
    "import numpy as np\n",
    "\n",
    "ndvi_images = []\n",
    "pan_images = [] \n",
    "annotations = [] \n",
    "boundaries = []\n",
    "\n",
    "# [1] \n",
    "# python /ar1/PROJ/fjuhsd/personal/thaddaeus/github/cnn-tree-heights/src/monthly/jan2023/library-testing/first_training_test.py > /ar1/PROJ/fjuhsd/personal/thaddaeus/other/cnn-heights/output/log.txt &\n",
    "\n",
    "computer = 'wh1' # input('m2, wh1, or wsl: ')\n",
    "\n",
    "if computer == 'm2': \n",
    "    data_dir = '/Users/yaroslav/Documents/Work/NASA/data/first_mosaic/rebuilt_approach/output/'\n",
    "    logging_dir = '/Users/yaroslav/Documents/GitHub/cnn-tree-heights/src/monthly/jan2023/library-testing/cnn-training-output'\n",
    "\n",
    "elif computer == 'wh1': \n",
    "    data_dir = '/ar1/PROJ/fjuhsd/personal/thaddaeus/github/cnn-tree-heights/data/cnn-input/'\n",
    "    logging_dir = '/ar1/PROJ/fjuhsd/personal/thaddaeus/other/cnn-heights/output'\n",
    "\n",
    "elif computer == 'wsl': \n",
    "    data_dir = ''\n",
    "\n",
    "else:\n",
    "    raise Exception('Choose correct computer to work on!')\n",
    "\n",
    "for file in np.sort(os.listdir(data_dir)):\n",
    "    full_path = data_dir+file\n",
    "    if '.png' in file: \n",
    "        if 'annotation' in file: \n",
    "            annotations.append(full_path) \n",
    " \n",
    "        elif 'boundary' in file: \n",
    "            boundaries.append(full_path) \n",
    "\n",
    "        elif 'ndvi' in file: \n",
    "            ndvi_images.append(full_path) \n",
    "\n",
    "        elif 'extracted_pan' in file: \n",
    "            pan_images.append(full_path) \n",
    "\n",
    "model, hist = train_cnn(ndvi_images, pan_images, annotations, boundaries, logging_dir=logging_dir, epochs=1, training_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "Converting prediction from float32 to uint8, using threshold of 0.5\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fjuhsd/miniconda3/envs/cnnheights38/lib/python3.8/site-packages/geopandas/io/file.py:299: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Proj\n",
    "\n",
    "output_dir = '/ar1/PROJ/fjuhsd/personal/thaddaeus/github/cnn-tree-heights/src/monthly/feb2023/saving-predictions'\n",
    "predict(model, ndvi_images[0], pan_images[0], output_dir=output_dir, crs='EPSG:32628') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fjuhsd/miniconda3/share/proj'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyproj\n",
    "pyproj.datadir.get_data_dir()\n",
    "#/home/fjuhsd/miniconda3/envs/cnnheights38/share/proj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnnheights38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "524e0016e4215525df0f5793c4407aa9a1f0f5d2f0fcea61a3368fecbc385c79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
